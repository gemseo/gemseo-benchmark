# -*- coding: utf-8 -*-
# Copyright 2021 IRT Saint ExupÃ©ry, https://www.irt-saintexupery.com
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License version 3 as published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program; if not, write to the Free Software Foundation,
# Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

# Contributors:
#    INITIAL AUTHORS - initial API and implementation and/or initial
#                           documentation
#        :author: Benoit Pauwels
#    OTHER AUTHORS   - MACROSCOPIC CHANGES
"""Class that generates performance measures out of data generated by an algorithm.

Iterative algorithms that solve, for example, optimization problems or equations
produce histories of data such as the value of the objective to minimize,
or the size of the equation residual, at each iteration.
The best value obtained up until each iteration can be generated out of this data.
Here we call "performance history" the history of the best values obtained up until
each iteration.

Infeasible data can be discarded based upon histories of infeasibility measures or
boolean feasibility statuses.

Performance histories can be used to generate target values for a problem,
or to generate the data profile of an algorithm.
"""
import json
from functools import reduce
from typing import Iterable, List, Optional, Sequence, Union

from gemseo.algos.opt_problem import OptimizationProblem
from gemseo.utils.py23_compat import Path
from numpy import inf

from gemseo_benchmark.results.history_item import HistoryItem
from gemseo_benchmark.utils import (get_n_unsatisfied_constraints,
                                    get_scalar_constraints_names)


class PerformanceHistory(Sequence[HistoryItem]):
    """A history of performance measures generated by an algorithm.

    A `PerformanceHistory` is a sequence of `HistoryItem`s.

    Attributes:
        history_items (List[HistoryItem]): The items of the performance history.
        max_eval (int): The maximum number of functions evaluations.
        nbr_eval_iter (int): The number of functions evaluations per iteration.
        problem_name (str): The name of the problem.
        total_time (float): The run time of the algorithm.
    """
    __PERFORMANCE = "performance"
    __INFEASIBILITY = "infeasibility"
    __N_UNSATISFIED_CONSTRAINTS = "n_unsatisfied_constraints"

    def __init__(
            self,
            objective_values=None,  # type: Optional[Sequence[float]]
            infeasibility_measures=None,  # type: Optional[Sequence[float]]
            feasibility_statuses=None,  # type: Optional[Sequence[bool]]
            n_unsatisfied_constraints=None,  # type: Optional[Sequence[int]]
            problem_name=None,  # type: Optional[str]
            objective_name=None,  # type: Optional[str]
            constraints_names=None,  # type: Optional[Sequence[str]]
            doe_size=None,  # type: Optional[int]
            nbr_eval_iter=None,  # type: Optional[int]
            population_size=None,  # type: Optional[int]
            total_time=None,  # type: Optional[float]
            algorithm=None,  # type: Optional[str]
            max_eval=None,  # type: Optional[int]
    ):  # type: (...) -> None
        """
        Args:
            objective_values: The history of the quantity to be minimized.
                If None, will be considered empty.
            infeasibility_measures: The history of infeasibility measures.
                An infeasibility measure is a non-negative real number representing
                the gap between the design and the feasible space,
                a zero value meaning feasibility.
                If None and `feasibility_statuses` is not None
                then the infeasibility measures are set to zero in case of feasibility,
                and set to infinity otherwise.
                If None and `feasibility_statuses` is None
                then every infeasibility measure is set to zero.
            feasibility_statuses: The history of the (boolean) feasibility statuses.
                If `infeasibility_measures` is not None then `feasibility_statuses` is
                disregarded.
                If None and 'infeasibility_measures' is None
                then every infeasibility measure is set to zero.
            n_unsatisfied_constraints: The history of the number of unsatisfied
                constraints.
                If None, the entries will be set to 0 for feasible entries
                and None for infeasible entries.
            problem_name: The name of the problem.
                If None, it will not be set.
            objective_name: The name of the objective function.
                If None, it will not be set.
            constraints_names: The names the scalar constraints.
                Each name must correspond to a scalar value.
                If None, it will not be set.
            doe_size: The size of the initial design of experiments.
                If None, it will not be set.
            nbr_eval_iter: The number of functions evaluations per iteration.
                If None, it will not be set.
            population_size: The size of the optimizer population.
                If None, it will not be set.
            total_time: The total time of the optimization, in seconds.
                If None, it will not be set.
            algorithm: The name of the algorithm which generated the history.
                If None, it will not be set.
            max_eval: The maximum number of functions evaluations.
                If None, it will not be set.

        Raises:
            ValueError: If the lengths of the histories do not match.
        """
        if constraints_names is None:
            self._constraints_names = []
        else:
            self._constraints_names = constraints_names

        self._objective_name = objective_name
        self.algorithm = algorithm
        self.doe_size = doe_size
        self.history_items = self.__get_history_items(
            objective_values, infeasibility_measures, feasibility_statuses,
            n_unsatisfied_constraints,
        )
        self.max_eval = max_eval
        self.nbr_eval_iter = nbr_eval_iter
        self.population_size = population_size
        self.problem_name = problem_name
        self.total_time = total_time

    @property
    def objective_values(self):  # type: (...) -> List[float]
        """The objective values."""
        return [item.objective_value for item in self.history_items]

    @property
    def infeasibility_measures(self):  # type: (...) -> List[float]
        """The infeasibility measures."""
        return [item.infeasibility_measure for item in self.history_items]

    @property
    def n_unsatisfied_constraints(self):  # type: (...) -> List[int]
        """The numbers of unsatisfied constraints."""
        return [item.n_unsatisfied_constraints for item in self.history_items]

    @property
    def history_items(self):  # type: (...) -> List[HistoryItem]
        """The history items.

        Raises:
            TypeError: If an item is set with a type different from HistoryItem.
        """
        return self.__items

    @history_items.setter
    def history_items(
            self,
            history_items,  # type: Iterable[HistoryItem]
    ):  # type: (...) -> None
        for item in history_items:
            if not isinstance(item, HistoryItem):
                raise TypeError(
                    "History items must be of type HistoryItem."
                    " The following type was passed: {}.".format(type(item))
                )
        self.__items = list(history_items)

    @staticmethod
    def __get_history_items(
            objective_values=None,  # type: Optional[Sequence[float]]
            infeasibility_measures=None,  # type: Optional[Sequence[float]]
            feasibility_statuses=None,  # type: Optional[Sequence[bool]]
            n_unsatisfied_constraints=None,  # type: Optional[Sequence[int]]
    ):  # type: (...) -> List[HistoryItem]
        """Return history items based on values histories.

        Args:
            objective_values: The history of the quantity to be minimized.
                If None, will be considered empty.
            infeasibility_measures: The history of infeasibility measures.
                An infeasibility measure is a non-negative real number representing
                the gap between the design and the feasible space,
                a zero value meaning feasibility.
                If None and `feasibility_statuses` is not None
                then the infeasibility measures are set to zero in case of feasibility,
                and set to infinity otherwise.
                If None and `feasibility_statuses` is None
                then every infeasibility measure is set to zero.
            feasibility_statuses: The history of the (boolean) feasibility statuses.
                If `infeasibility_measures` is not None then `feasibility_statuses` is
                disregarded.
                If None and 'infeasibility_measures' is None
                then every infeasibility measure is set to zero.
            n_unsatisfied_constraints: The history of the number of unsatisfied
                constraints.
                If None, the entries will be set to 0 for feasible entries
                and None for infeasible entries.

        Returns:
            The history items.
        """
        if objective_values is None:
            objective_values = []

        if infeasibility_measures is not None:
            if len(infeasibility_measures) != len(objective_values):
                raise ValueError("The objective history and the infeasibility history "
                                 "must have same length.")
        elif feasibility_statuses is not None:
            if len(feasibility_statuses) != len(objective_values):
                raise ValueError("The objective history and the feasibility history "
                                 "must have same length.")
            infeasibility_measures = [
                0.0 if is_feas else inf for is_feas in feasibility_statuses
            ]
        else:
            infeasibility_measures = [0.0] * len(objective_values)

        if n_unsatisfied_constraints is None:
            n_unsatisfied_constraints = [
                0 if entry == 0.0 else None for entry in infeasibility_measures
            ]
        elif len(n_unsatisfied_constraints) != len(infeasibility_measures):
            raise ValueError(
                "The unsatisfied constraints history and the feasibility history"
                " must have same length."
            )

        return [
            HistoryItem(value, measure, n_unsatisfied) for value, measure, n_unsatisfied
            in zip(objective_values, infeasibility_measures, n_unsatisfied_constraints)
        ]

    def __len__(self):  # type: (...) -> int
        return len(self.__items)

    def __getitem__(
            self,
            i,  # type: int
    ):  # type: (...) -> HistoryItem
        return self.__items[i]

    def __repr__(self):  # type: (...) -> str
        return str([item for item in self])

    def compute_cumulated_minimum(self):  # type: (...) -> PerformanceHistory
        """Return the history of the cumulated minimum.

        Returns:
            The history of the cumulated minimum.
        """
        minima = [reduce(min, self.__items[:i + 1]) for i in range(len(self))]
        minimum_history = PerformanceHistory()
        minimum_history.history_items = minima
        return minimum_history

    def __compute_median(self):  # type: (...) -> HistoryItem
        """Return the median of the history of performance values.

        Returns:
            The median of the history of performance values.
        """
        # Compute the middle index of the items (N.B. zero-based index)
        if len(self) % 2 == 0:
            middle_index = len(self) // 2 - 1
        else:
            middle_index = len(self) // 2
        return sorted(self.__items)[middle_index]

    @staticmethod
    def compute_median_history(
            histories  # type: Iterable[PerformanceHistory]
    ):  # type: (...) -> PerformanceHistory
        """Return the history of the median of several performance histories.

        Args:
            histories: The performance histories

        Returns:
            The median history.
        """
        medians = list()
        # Iterate over the sets of history items corresponding to the same iteration
        # and compute their medians
        for snapshot in zip(*[hist.history_items for hist in histories]):
            snapshot_as_hist = PerformanceHistory()
            snapshot_as_hist.history_items = snapshot
            median = snapshot_as_hist.__compute_median()
            medians.append(median)
        median_history = PerformanceHistory()
        median_history.history_items = medians
        return median_history

    def remove_leading_infeasible(self):  # type: (...) -> PerformanceHistory
        """Return the history starting from the first feasible item.

        Returns:
            The truncated performance history.
        """
        first_feasible = None
        for index, item in enumerate(self):
            if item.infeasibility_measure == 0.0:
                first_feasible = index
                break
        truncated_history = PerformanceHistory()
        if first_feasible is not None:
            truncated_history.history_items = self.history_items[first_feasible:]
        return truncated_history

    def to_file(
            self,
            path,  # type: Union[str, Path]
    ):  # type: (...) -> None
        """Save the performance history in a file.

        Args:
            path: The path where to write the file.
        """
        data = list()
        # Add each history item in dictionary format
        for item in self.history_items:
            data_item = {
                PerformanceHistory.__PERFORMANCE: item.objective_value,
                PerformanceHistory.__INFEASIBILITY: item.infeasibility_measure,
            }
            if item.n_unsatisfied_constraints is not None:
                data_item[PerformanceHistory.__N_UNSATISFIED_CONSTRAINTS] = \
                    item.n_unsatisfied_constraints

            data.append(data_item)

        with Path(path).open("w") as file:
            json.dump(data, file, indent=4, separators=(',', ': '))

    @classmethod
    def from_file(
            cls,
            path,  # type: Union[str, Path]
    ):  # type: (...) -> PerformanceHistory
        """Create a new performance history from a file.

        Args:
            path: The path to the file.

        Returns:
            The performance history.
        """
        with Path(path).open("r") as file:
            data = json.load(file)
        objective_values = list()
        infeasibility_measures = list()
        for item in data:
            objective_values.append(item[PerformanceHistory.__PERFORMANCE])
            infeasibility_measures.append(item[PerformanceHistory.__INFEASIBILITY])
        return cls(objective_values, infeasibility_measures)

    @classmethod
    def from_problem(
            cls,
            problem,  # type: OptimizationProblem
            problem_name=None,  # type: Optional[str]
    ):  # type: (...) -> PerformanceHistory
        """Create a performance history from a solved optimization problem.

        Args:
            problem: The optimization problem.
            problem_name: The name of the problem.
                If None, the name of the problem is not set.

        Returns:
            The performance history.
        """
        obj_name = problem.objective.name
        obj_values = list()
        infeas_measures = list()
        feas_statuses = list()
        n_unsatisfied_constraints = list()
        for design_values, output_values in problem.database.items():
            if obj_name in output_values:
                obj_values.append(output_values[obj_name])
                feasibility, measure = problem.get_violation_criteria(design_values)
                infeas_measures.append(measure)
                feas_statuses.append(feasibility)
                n_unsatisfied_constraints.append(int(get_n_unsatisfied_constraints(
                    problem, design_values
                )))

        return PerformanceHistory(
            obj_values, infeas_measures, feas_statuses, n_unsatisfied_constraints,
            problem_name, problem.objective.name, get_scalar_constraints_names(problem)
        )
