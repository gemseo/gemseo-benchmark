# -*- coding: utf-8 -*-
# Copyright 2022 IRT Saint Exup√©ry, https://www.irt-saintexupery.com
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License version 3 as published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program; if not, write to the Free Software Foundation,
# Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

# Contributors:
#    INITIAL AUTHORS - initial API and implementation and/or initial
#                           documentation
#        :author: Benoit Pauwels
#    OTHER AUTHORS   - MACROSCOPIC CHANGES
r"""Benchmarking of algorithms.

The :mod:`gemseo-benchmark` package provides functionalities to benchmark optimization
algorithms.

.. note:: Other algorithms will be supported in the future.
   E.g. root-finding algorithms.


Benchmarking problem
--------------------

The :mod:`~gemseo-benchmark.problems` sub-package handles the benchmarking problems and
groups of problems.

A :class:`Problem` contains:

* the definition of the benchmarking problem,
  e.g. the functions of an :class:`.OptimizationProblem`,
* the starting points for the algorithms,
* the target values of problem, necessary to compute
  :ref:`data profiles <data-profiles>`.


Performance history
-------------------

The :mod:`gemseo-benchmark.results` sub-package manages the results of the benchmarked
algorithms.

The history of the data produced by an algorithm is stored in a
:class:`PerformanceHistory`.
#. A value of interest in the benchmarking of algorithms is defined and named
*performance value*.
   The most telling performance value is
   the value of the objective function for an optimization problem,
   or the value of a residual for a nonlinear equation.
#. This performance value is stored in a :class:`HistoryItem`,
   along with an infeasibility measure (especially for problems subject to constraints).
#. This :class:`.HistoryItem` is appended to a :class:`PerformanceHistory`,
   which is a sequence of :class:`HistoryItem`\\ s.
   The index of the sequence is understood as the 0-based number of functions
   evaluations.


.. _data-profile:

Data profile
------------

The **data_profile** sub-package handles the computation of the data profiles.

A *data profile* is a graph that represents the extent to which an algorithm solves a
problem (or a group of problems) for a given number of functions evaluations.

Target values
^^^^^^^^^^^^^

The difficulty of a benchmarking problem is represented by a scale of performance
values, called *target values*, ranging from a relatively easily achievable value to
the best value known.
The most telling example of target value is the optimal value of the objective function.
Target values can be thought as milestones on the trajectory towards the best value
known.

Since target values are performance values, :class:`TargetValues` is a subclass of
:class:`PerformanceHistory`.

Targets generator
^^^^^^^^^^^^^^^^^

The target values of a problem can be handpicked but they can also be automatically
computed with a generator of target values.

A :class:`TargetsGenerator` relies on algorithms chosen as references:

#. the problem is solved with the reference algorithms from each starting point,
#. instances of :class:`PerformanceHistory` representing the history of the best
   performance value (which is decreasing) are computed,
   e.g. :math:`\left(\min_{0\leq i \leq k} f(x_i)\right)_{0 \leq k \leq K}`
   where :math:`f` is the cost function 
   and :math:`x_k` are the values of the design variables at iteration :math:`k`,
#. a notion of *median history* is computed from these histories,
#. performance values are picked at uniform intervals in the median history:
   these are the target values.

Data profile
^^^^^^^^^^^^

The *data profile* of an algorithm relative to a benchmarking problem
(or a group of benchmarking problems)
is the graph representing the ratio of target values reached by the algorithm
relative to the number functions evaluations performed by the algorithm.


Report
------

The :mod:`~gemseo_benchmark.report` sub-package manages the automatic generation of a
benchmarking report.

The :class:`Report` produces
`reStructuredText (reST) <https://docutils.sourceforge.io/rst.html>`_ files describing:

* the benchmarking problems,
* the benchmarked algorithms,
* the results generated by the algorithms on the problems, 
  especially in the form of data profiles.
"""
import itertools
import re
from typing import Iterator, List, Tuple, Union

import matplotlib

MarkeveryType = Union[
    None, int, Tuple[int, int], slice, List[int], float, Tuple[float, float], List[bool]
]
# The colors cycle for the plots
COLORS_CYCLE = matplotlib.rcParams["axes.prop_cycle"].by_key()["color"]
# The markers for the plots
MARKERS = ('o', 's', 'D', 'v', '^', '<', '>', 'X', 'H', 'p')


def get_markers_cycle() -> Iterator:
    """Return the markers cycle for the plots.

    Returns:
        The markers cycle.
    """
    return itertools.cycle(MARKERS)


def join_substrings(string: str) -> str:
    """Join sub-strings with underscores.

    Args:
        string: The string.

    Returns:
        The joined sub-strings.
    """
    return re.sub(r"\s+", '_', string)
