{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompute data profiles\n=====================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example,\nwe compute the **data profiles** of three algorithms configurations\nbased on two reference problems.\n\nImports\n-------\nWe start by making the necessary imports.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport shutil\nimport tempfile\nfrom pathlib import Path\n\nfrom gemseo import configure\nfrom gemseo.problems.optimization.rastrigin import Rastrigin\nfrom gemseo.problems.optimization.rosenbrock import Rosenbrock\n\nfrom gemseo_benchmark.algorithms.algorithm_configuration import AlgorithmConfiguration\nfrom gemseo_benchmark.algorithms.algorithms_configurations import (\n    AlgorithmsConfigurations,\n)\nfrom gemseo_benchmark.data_profiles.target_values import TargetValues\nfrom gemseo_benchmark.problems.problem import Problem\nfrom gemseo_benchmark.problems.problems_group import ProblemsGroup\nfrom gemseo_benchmark.scenario import Scenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the algorithms configurations\n---------------------------------\nLet us define the algorithms configurations\nfor which we want to compute data profiles.\n\nFor example,\nlet us choose a configuration of the L-BFGS-B algorithm\nwith a number of Hessian corrections limited to 2.\n(This option is called `maxcor`.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lbfgsb_2_corrections = AlgorithmConfiguration(\n    \"L-BFGS-B\",\n    \"L-BFGS-B with 2 Hessian corrections\",\n    maxcor=2,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note:\n    The customized name `\"L-BFGS-B with 2 Hessian corrections\"`\n    will serve as label in the plot of the data profiles.\n\nTo investigate the influence of the ``maxcor`` option,\nlet us consider a different configuration of L-BFGS-B\nwith up to 20 Hessian corrections.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lbfgsb_20_corrections = AlgorithmConfiguration(\n    \"L-BFGS-B\",\n    \"L-BFGS-B with 20 Hessian corrections\",\n    maxcor=20,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Additionally,\nlet us choose the SLSQP algorithm,\nwith all its options set to their default values,\nto compare it against L-BFGS-B.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "slsqp_default = AlgorithmConfiguration(\"SLSQP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we gather our selection of algorithms configurations in a group.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algorithms_configurations = AlgorithmsConfigurations(\n    lbfgsb_2_corrections,\n    lbfgsb_20_corrections,\n    slsqp_default,\n    name=\"Derivative-based algorithms\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the reference problems\n--------------------------\nLet us choose two problems already implemented in GEMSEO as references\nto measure the performances of our selection of algorithms configurations:\n[Rastrigin][gemseo.problems.optimization.rastrigin.Rastrigin]\nand [Rosenbrock][gemseo.problems.optimization.rosenbrock.Rosenbrock].\n\nWe define target values as an exponential scale of values decreasing towards zero,\nthe minimum value of both Rastrigin's and Rosenbrock's functions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimum = 0.0\ntarget_values = TargetValues([10**-i for i in range(4, 7)] + [optimum])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note:\n    It could be preferable to customize a different scale of target values\n    for each problem, although we keep it simple here.\n\nWe now have all the elements to define the benchmarking problems.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rastrigin = Problem(\n    \"Rastrigin\",\n    Rastrigin,\n    optimum=optimum,\n    doe_size=5,\n    doe_algo_name=\"OT_OPT_LHS\",\n    target_values=target_values,\n)\nrosenbrock = Problem(\n    \"Rosenbrock\",\n    Rosenbrock,\n    optimum=optimum,\n    doe_size=5,\n    doe_algo_name=\"OT_OPT_LHS\",\n    target_values=target_values,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we configure a design of experiments (DOE)\nto generate five starting points by optimized Latin hypercube sampling (LHS).\n\nFinally, we gather our reference problems in a group.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problems = ProblemsGroup(\"Reference problems\", [rastrigin, rosenbrock])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate the benchmarking results\n---------------------------------\nNow that the algorithms configurations and the reference problems are properly set,\nwe can measure the performances of the former on the latter.\n\nWe set up a [Scenario][gemseo_benchmark.scenario.Scenario] with\nour group of algorithms configurations\nand a path to a directory where to save the performance histories.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scenario_dir = Path(tempfile.mkdtemp())\nscenario = Scenario([algorithms_configurations], scenario_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we choose to deactivate the functions counters, progress bars and bounds check\nof GEMSEO to accelerate the script.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "configure(\n    enable_function_statistics=False,\n    enable_progress_bar=False,\n    check_desvars_bounds=False,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us execute the benchmarking scenario on our group of reference problems.\n\nNote:\n    Here we skip the generation of the report\n    as we only intend to compute the data profiles.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = scenario.execute([problems], skip_report=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the datas profiles\n--------------------------\nNow that the performances histories are generated for the reference problems,\nthe data profiles of the algorithms configurations can be computed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problems.compute_data_profile(algorithms_configurations, results, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we remove the performances histories as we do not wish to keep them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shutil.rmtree(scenario_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}